{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\train-phi-3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import onnxruntime_genai as og\n",
    "\n",
    "# prompt = \"Why is the sky blue?\"\n",
    "prompt = \"<|user|>Tell me a NASA joke!<|end|><|assistant|>\"\n",
    "\n",
    "modelpath = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "templates = [\n",
    "    \"<|im_start|>assistant\\n{msg}<|im_end|>\",\n",
    "    \"<|im_start|>user\\n{msg}<|im_end|>\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#############################################################################################################################\n",
    "# inferencing with the onnx model (after finetuning)\n",
    "#############################################################################################################################\n",
    "\n",
    "path_to_model_folder = 'finetune_results'\n",
    "model = og.Model(path_to_model_folder)\n",
    "tokenizer = og.Tokenizer(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 29871, 32007, 285, 12443, 25467], '')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<|end|> fghjk\"), tokenizer.decode([1, 29871, 32007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <|im_end|>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([529, 29989, 326, 29918, 355, 29989, 29958])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 529, 29989, 326, 29918, 2962, 29989, 29958, 1792, 13, 29902, 626, 3907, 1122, 11586, 895, 29892, 372, 471, 6257, 304, 12003, 264, 541, 1286, 372, 756, 4953, 1065, 1460, 322, 23904, 1449, 29892, 338, 727, 738, 982, 304, 24754, 482, 372, 29973, 29966, 29989, 326, 29918, 355, 29989, 29958, 32013, 29871, 32011, 29871, 32011, 465, 22137, 13, 29902, 626, 385, 319, 29902, 4086, 1904, 29889, 32013, 29871, 32011, 32013, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011, 29871, 32011]]\n",
      "<|im_start|>user\n",
      "I am making mayonnaise, it was starting to thicken but now it has become runny and liquid again, is there any way to salvage it?<|im_end|>assistant\n",
      "I am an AI language model.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<|im_start|>user\\nI am making mayonnaise, it was starting to thicken but now it has become runny and liquid again, is there any way to salvage it?<|im_end|>\"\n",
    "# prompt = \"<|user|>Tell me a NASA joke!<|end|>\"\n",
    "tokens = tokenizer.encode(prompt)\n",
    "\n",
    "params = og.GeneratorParams(model)\n",
    "# params.set_search_options({\"max_length\": 20})\n",
    "params.set_search_options(max_length=150)\n",
    "# params.set_search_options(max_length=400, top_k = 50, top_p = 0.95)\n",
    "params.input_ids = tokens\n",
    "\n",
    "generated_output = model.generate(params)\n",
    "print(generated_output)\n",
    "\n",
    "output_tokens = generated_output[0]\n",
    "\n",
    "text = tokenizer.decode(output_tokens)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<onnxruntime_genai.onnxruntime_genai.GeneratorParams at 0x1f8447e3230>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train-phi-3-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
